# Quiz for FastAI lesson 5

[fastai lesson 5](https://course.fast.ai/videos/?lesson=5)

1. Jeremy uses the `map` function to turn `np.array`s into `pytorch.tensor`s. What is the `map` function?

1. Explain everything you can to your partner about the drawing that Jeremy made with all the layers. Try to use the following terms correctly as you do so.
    * parameters
    * activations
    * activation function
    * back propagation

1. What is the Universal Approximation Theorem?

1. What is `data.c` and what does it have to do with the shape of your activation tensor?

1. What does it mean to `freeze` a model?

1. What does it mean to use `discriminative learning rates`?

1. How does the `fit` function interpret the following learning rate values? `1e-3`, `slice(1e-3)`, `slice(1e-5, 1e-3)`

1. True / False : Affine function is a kind of matrix multiplication.

1. If you want the result of matrix multiplication to "copy"/"select" a row of a matrix, what should the other matrix look like?

1. What is a latent factor (or latent feature), as it relates to embeddings?

1. What is `bias`?

1. What is the difference between `1-hot encoding` and `n-hot encoding`?

1. Why would you make your sigmoid function for final activation have a range bigger than the actual range that you are trying to predict?

1. What is Principle Component Analysis?

1. What is regularization? What is weight decay? (*HINT:* What is the relation between over-fitting, the number of parameters that a model can have, and the weights of those parameters?)

1. What is SGD?

1. What is a dynamic learning rate?

1. What is momentum? RMSProp? Adam?

1. What does `fit_one_cycle` do with the learning rate?

1. Why doesn't Mean Square Error work well as a loss function for classification tasks?

1. What is Cross Entropy Loss?

1. What is the purpose of the `softmax` function?
